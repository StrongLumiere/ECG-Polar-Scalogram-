{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polar Scalogram Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.signal import resample\n",
    "import numpy as np\n",
    "import neurokit2 as nk\n",
    "import pywt\n",
    "import seaborn as sns\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Code Works\\Work\\vscode\\ecgproject\\Spectrogram\\training2017\n"
     ]
    }
   ],
   "source": [
    "# 현재 경로 불러오기 = os.getcwd()\n",
    "path = os.getcwd()\n",
    "os.chdir(path+ \"\\\\training2017\")\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv='REFERENCE.csv'\n",
    "data = pd.read_csv(csv, header=None, names=['ID', 'Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ECG READ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecg_read(patient_id):\n",
    "    record = wfdb.rdrecord(patient_id) \n",
    "    ecg_signal = record.p_signal[:,0]  \n",
    "    fs = record.fs\n",
    "    return ecg_signal, fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Labeling:  Dictionary for ALL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =[] # Atrial Fibrillation\n",
    "N= [] # Normal Sinus rhythm\n",
    "O = [] # Other rhythm\n",
    "I = [] # Noisy\n",
    "\n",
    "for id, lb in zip (data['ID'], data['Label'] ): #v2 data\n",
    "         \n",
    "         if lb =='A':\n",
    "            A.append(id)\n",
    "            \n",
    "         elif lb =='N':\n",
    "            N.append(id)\n",
    "         \n",
    "         elif lb =='O':\n",
    "            O.append(id)\n",
    "        \n",
    "         elif lb =='~':\n",
    "            I.append(id)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_all = {'Atrial Fibrillation': A, 'Normal Sinus Rhythm': N, 'Other Rhythm': O, 'Noisy': I}\n",
    "# print(len(A))\n",
    "# print(len(N))\n",
    "# print(len(O))\n",
    "# print(len(I))\n",
    "# print(len(A)+len(N)+len(O)+len(I))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Dictionary for 30s data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A_30 =[] # Atrial Fibrillation\n",
    "# N_30= [] # Normal Sinus rhythm\n",
    "# O_30 = [] # Other rhythm\n",
    "# I_30 = [] # Noisy\n",
    "# id_30=[]\n",
    "\n",
    "\n",
    "# # 30초 아이디 찾기기\n",
    "# for id, lb in zip(data['ID'], data['Label']):\n",
    "\n",
    "#     ecg_signal, fs=ecg_read(id)\n",
    "#     time = np.arange(ecg_signal.shape[0]) / fs\n",
    "\n",
    "#     if int(len(time)/fs) == 30:\n",
    "#         id_30.append(id)\n",
    "\n",
    "\n",
    "# # 30초 아이디 라벨 매칭칭\n",
    "# for id, lb in zip(data['ID'], data['Label']):  # 원본 데이터에서 ID와 라벨을 반복\n",
    "#     if id in id_30:  # ID가 id_30 리스트에 있는지 확인\n",
    "#         if lb == 'A':\n",
    "#             A_30.append(id)\n",
    "#         elif lb == 'N':\n",
    "#             N_30.append(id)\n",
    "#         elif lb == 'O':\n",
    "#             O_30.append(id)\n",
    "#         elif lb == '~':\n",
    "#             I_30.append(id)\n",
    "\n",
    "\n",
    "# # 30초 데이터에 관한 dictionary\n",
    "# dic_30 = {\n",
    "#     \"Atrial Fibrillation\": A_30,\n",
    "#     \"Normal Sinus Rhythm\": N_30,\n",
    "#     \"Other Rhythm\": O_30,\n",
    "#     \"Noisy\": I_30\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> nomalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_ecg(ecg_signal):\n",
    "    min_val = np.min(ecg_signal)\n",
    "    max_val = np.max(ecg_signal)\n",
    "    normalized_signal = (ecg_signal - min_val) / (max_val - min_val)\n",
    "    return normalized_signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Resampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample ECG signal from original sampling rate to target sampling rate -> 해상도\n",
    "def resample_ecg_signal(ecg_signal, original_fs, target_fs):\n",
    "    num_samples = int(len(ecg_signal) * target_fs / original_fs)\n",
    "    resampled_signal = resample(ecg_signal, num_samples)\n",
    "    return resampled_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> PT\n",
    "#### Acknowledgements ####\n",
    "\n",
    "This project utilizes code from [Pramod07Ch](https://github.com/Pramod07Ch). Their contributions have been invaluable to the development of this project. You can find the original repository [here](https://github.com/Pramod07Ch/Pan-Tompkins-algorithm-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt\n",
    "class Pan_tompkins:\n",
    "    \"\"\" Implementationof Pan Tompkins Algorithm.\n",
    "\n",
    "    Noise cancellation (bandpass filter) -> Derivative step -> Squaring and integration.\n",
    "\n",
    "    Params:\n",
    "        data (array) : ECG data\n",
    "        sampling rate (int)\n",
    "    returns:\n",
    "        Integrated signal (array) : This signal can be used to detect peaks\n",
    "\n",
    "\n",
    "    ----------------------------------------\n",
    "    HOW TO USE ?\n",
    "    Eg.\n",
    "\n",
    "    ECG_data = [4, 7, 80, 78, 9], sampling  =2000\n",
    "    \n",
    "    call : \n",
    "       signal = Pan_tompkins(ECG_data, sampling).fit()\n",
    "\n",
    "    ----------------------------------------\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, data, sample_rate):\n",
    "\n",
    "        self.data = data\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "\n",
    "    def fit(self, normalized_cut_offs=None, butter_filter_order=2, padlen=150, window_size=None):\n",
    "        ''' Fit the signal according to algorithm and returns integrated signal\n",
    "        \n",
    "        '''\n",
    "        # 1.Noise cancellationusing bandpass filter\n",
    "        self.filtered_BandPass = self.band_pass_filter(normalized_cut_offs, butter_filter_order, padlen)\n",
    "        \n",
    "        # 2.derivate filter to get slpor of the QRS\n",
    "        self.derviate_pass = self.derivative_filter()\n",
    "\n",
    "        # 3.Squaring to enhance dominant peaks in QRS\n",
    "        self.square_pass = self.squaring()\n",
    "\n",
    "        # 4.To get info about QRS complex\n",
    "        self.integrated_signal = self.moving_window_integration( window_size)\n",
    "\n",
    "        return self.integrated_signal\n",
    "\n",
    "\n",
    "    def band_pass_filter(self, normalized_cut_offs=None, butter_filter_order=2, padlen=150):\n",
    "        ''' Band pass filter for Pan tompkins algorithm\n",
    "            with a bandpass setting of 5 to 20 Hz\n",
    "\n",
    "            params:\n",
    "                normalized_cut_offs (list) : bandpass setting canbe changed here\n",
    "                bandpass filte rorder (int) : deffault 2\n",
    "                padlen (int) : padding length for data , default = 150\n",
    "                        scipy default value = 2 * max(len(a coeff, b coeff))\n",
    "\n",
    "            return:\n",
    "                filtered_BandPass (array)\n",
    "        '''\n",
    "\n",
    "        # Calculate nyquist sample rate and cutoffs\n",
    "        nyquist_sample_rate = self.sample_rate / 2\n",
    "\n",
    "        # calculate cutoffs\n",
    "        if normalized_cut_offs is None:\n",
    "            normalized_cut_offs = [5/nyquist_sample_rate, 15/nyquist_sample_rate]\n",
    "        else:\n",
    "            assert type(self.sample_rate ) is list, \"Cutoffs should be a list with [low, high] values\"\n",
    "\n",
    "        # butter coefficinets \n",
    "        b_coeff, a_coeff = butter(butter_filter_order, normalized_cut_offs, btype='bandpass')[:2]\n",
    "\n",
    "        # apply forward and backward filter\n",
    "        filtered_BandPass = filtfilt(b_coeff, a_coeff, self.data, padlen=padlen)\n",
    "        \n",
    "        return filtered_BandPass\n",
    "\n",
    "\n",
    "    def derivative_filter(self):\n",
    "        ''' Derivative filter\n",
    "\n",
    "        params:\n",
    "            filtered_BandPass (array) : outputof bandpass filter\n",
    "        return:\n",
    "            derivative_pass (array)\n",
    "        '''\n",
    "\n",
    "        # apply differentiation\n",
    "        derviate_pass= np.diff(self.band_pass_filter())\n",
    "\n",
    "       \n",
    "\n",
    "        return derviate_pass\n",
    "\n",
    "\n",
    "    def squaring(self):\n",
    "        ''' squaring application on derivate filter output data\n",
    "\n",
    "        params:\n",
    "\n",
    "        return:\n",
    "            square_pass (array)\n",
    "        '''\n",
    "\n",
    "        # apply squaring\n",
    "        square_pass= self.derivative_filter() **2\n",
    "\n",
    "        return square_pass \n",
    "\n",
    "\n",
    "    def moving_window_integration(self, window_size=None):\n",
    "        ''' Moving avergae filter \n",
    "\n",
    "        Params:\n",
    "            window_size (int) : no. of samples to average, if not provided : 0.08 * sample rate\n",
    "            sample_rate (int) : should be given if window_size is not given  \n",
    "        return:\n",
    "            integrated_signal (array)\n",
    "        '''\n",
    "\n",
    "        if window_size is None:\n",
    "            assert self.sample_rate is not None, \"if window size is None, sampling rate should be given\"\n",
    "            window_size = int(0.08 * int(self.sample_rate))  # given in paper 150ms as a window size\n",
    "        \n",
    "\n",
    "        # define integrated signal\n",
    "        integrated_signal = np.zeros_like(self.squaring())\n",
    "\n",
    "        # cumulative sum of signal\n",
    "        cumulative_sum = self.squaring().cumsum()\n",
    "\n",
    "        # estimationof area/ integral below the curve deifnes the data\n",
    "        integrated_signal[window_size:] = (cumulative_sum[window_size:] - cumulative_sum[:-window_size]) / window_size\n",
    "\n",
    "        integrated_signal[:window_size] = cumulative_sum[:window_size] / np.arange(1, window_size + 1)\n",
    "\n",
    "        return integrated_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import scipy.signal as signal\n",
    "\n",
    "\n",
    "# Save polar spectrogram\n",
    "def save_polar_spectrogram(polar_data, T, R, save_path, id, image_size, dpi, vmin=None, vmax=None, cmap='turbo'):\n",
    "    fig_size_inch = (image_size[0] / dpi, image_size[1] / dpi)\n",
    "    fig, ax = plt.subplots(figsize=fig_size_inch, dpi=dpi, subplot_kw={'projection': 'polar'})\n",
    "    \n",
    "    \n",
    "    if vmin is not None and vmax is not None:\n",
    "        c = ax.pcolormesh(T, R, polar_data, shading='auto', cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    else:\n",
    "        c = ax.pcolormesh(T, R, polar_data, shading='auto', cmap=cmap)\n",
    "    \n",
    "    # Remove axis lines, labels, and ticks\n",
    "    ax.set_theta_zero_location('N')  # 0 degrees at the top\n",
    "    ax.set_theta_direction(-1)  # Clockwise direction\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Ensure there is no padding and no border around the image\n",
    "    plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)\n",
    "    ax.margins(0, 0)\n",
    "    ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "    ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "    \n",
    "    # Save the figure as a PNG image with a transparent background\n",
    "    plt.savefig(f'{save_path}/{id}.png', format='png', transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "    plt.savefig(os.path.join(save_path, id), transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Save Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Code Works\\Work\\vscode\\ecgproject\\Spectrogram\n"
     ]
    }
   ],
   "source": [
    "# 필요에 따라 설정\n",
    "base_save_path= path\n",
    "print(base_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Image parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECG 전처리 관련 파라미터\n",
    "target_fs = 300  # ecg resampling(해상도), 기본 300 \n",
    "Nomaliztion = None\n",
    "PT_denoised = False# Whether to apply Pantompkins denoising\n",
    "padding_length_s = None # 0.25씩 앞뒤로  패딩, 총 0.5 패딩\n",
    "alpha = 0.05# Tukey window  # 0.05 30초에서는 이게 나을지도? #0.2 실험용 이미지 or 0\n",
    "\n",
    "# Scalogram 관련 파라미터\n",
    "max_scale = 128\n",
    "wavelet = 'mexh'\n",
    "dbscale= False\n",
    "\n",
    "# 이미지 저장관련 파라미터\n",
    "image_size = (224,224)\n",
    "dpi = 100\n",
    "vmin= None#0  \n",
    "vmax=None# 0.87   #1.45   #1.33  db 최대값\n",
    "cmap = 'turbo'   #'nipy_spectral'#'turbo'  #nipy_spectral\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### img save (30s) : Polar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for label, patient_ids in dic_30.items():\n",
    "#     # 해당 리듬에 대한 폴더 생성\n",
    "#     if label == \"Atrial Fibrillation\":\n",
    "#         folder_name = \"A\"\n",
    "#     elif label == \"Normal Sinus Rhythm\":\n",
    "#         folder_name = \"N\"\n",
    "#     elif label == \"Other Rhythm\":\n",
    "#         folder_name = \"O\"\n",
    "#     elif label == \"Noisy\":\n",
    "#         folder_name = \"~\"\n",
    "\n",
    "#     save_path_directory = os.path.join(base_save_path, folder_name)\n",
    "#     if not os.path.exists(save_path_directory):\n",
    "#         os.makedirs(save_path_directory)\n",
    "\n",
    "#     # images_created=0    \n",
    "\n",
    "#     for patient_id in patient_ids:\n",
    "#         save_filename = f'{patient_id}'\n",
    "#         save_path_img = os.path.join(save_path_directory, f'{save_filename}.png')\n",
    "\n",
    "#         if os.path.exists(save_path_img):\n",
    "#             print(f\"Skipping {patient_id} already exist.\")\n",
    "#             continue\n",
    "\n",
    "#              # 폴더당 최대 이미지 생성 시\n",
    "#         # if images_created >= 10:\n",
    "#         #     break\n",
    "#         # images_created+=1\n",
    "\n",
    "#         print(f\"Processing {patient_id}\")\n",
    "        \n",
    "#         ecg_signal, fs = ecg_read(patient_id)\n",
    "        \n",
    "#         if np.isnan(ecg_signal).any():\n",
    "#             ecg_signal = np.nan_to_num(ecg_signal, nan=0.0)\n",
    "\n",
    "\n",
    "#         if PT_denoised:\n",
    "#             # try:\n",
    "#             #     signals, info = nk.ecg_process(ecg_signal, sampling_rate=fs, method='pantompkins1985')\n",
    "#             #     if np.isnan(signals[\"ECG_Clean\"]).any():\n",
    "#             #         signals[\"ECG_Clean\"] = np.nan_to_num(signals[\"ECG_Clean\"], nan=0.0)\n",
    "#             #     ecg_signal = signals[\"ECG_Clean\"]\n",
    "#             # except Exception as e:\n",
    "#             #     print(f\"Error processing ECG signal with Pantompkins: {e}\")\n",
    "#             #     try:\n",
    "#             #         ecg_filtered = nk.ecg_clean(ecg_signal, sampling_rate=fs, method=\"biosppy\")\n",
    "#             #         signals, info = nk.ecg_process(ecg_filtered, sampling_rate=fs, method='pantompkins1985')\n",
    "#             #         if np.isnan(signals[\"ECG_Clean\"]).any():\n",
    "#             #             signals[\"ECG_Clean\"] = np.nan_to_num(signals[\"ECG_Clean\"], nan=0.0)\n",
    "#             #         ecg_signal = signals[\"ECG_Clean\"]\n",
    "#             #     except Exception as e:\n",
    "#             #         print(f\"Error processing ECG signal with Pantompkins after biosppy filtering: {e}\")\n",
    "\n",
    "#             pt_tompkins = Pan_tompkins(ecg_signal,fs).fit()\n",
    "#             ecg_signal = pt_tompkins\n",
    "\n",
    "#         if Nomaliztion:\n",
    "#             ecg_signal= normalize_ecg(ecg_signal)       \n",
    "                  \n",
    "\n",
    "#         if target_fs != 300:\n",
    "#             ecg_signal = resample_ecg_signal(ecg_signal, fs, target_fs)\n",
    "#             fs = target_fs \n",
    "        \n",
    "#         if padding_length_s ==0 or padding_length_s == None :\n",
    "#             padding_length =0\n",
    "#             ecg_signal_padded=ecg_signal\n",
    "#         else:    \n",
    "#             padding_length = int(target_fs / padding_length_s)\n",
    "#             # ecg_signal_padded = np.pad(ecg_signal, (padding_length, padding_length), 'constant', constant_values=(0, 0))\n",
    "#             ecg_signal_padded = np.pad(ecg_signal, (padding_length, padding_length), mode='reflect')\n",
    "\n",
    "#         if alpha:\n",
    "#             tukey_window = signal.windows.tukey(len(ecg_signal_padded), alpha=alpha)\n",
    "#             ecg_signal_padded *= tukey_window\n",
    "#         else:    \n",
    "#             ecg_signal_padded=ecg_signal_padded\n",
    "\n",
    "#         scales = np.arange(1, max_scale + 1)\n",
    "#         wavelet_coeffs, freqs = pywt.cwt(ecg_signal_padded, scales, wavelet, sampling_period=1/fs)\n",
    "\n",
    "#         if np.isnan(wavelet_coeffs).any():\n",
    "#             wavelet_coeffs = np.nan_to_num(wavelet_coeffs, nan=0.0)\n",
    "\n",
    "#         times_padded = np.linspace(0, len(ecg_signal_padded) / fs, len(ecg_signal_padded))\n",
    "#         theta = 2 * np.pi * times_padded / max(times_padded)\n",
    "#         rho = np.linspace(0.1, max_scale, max_scale)\n",
    "#         T, R = np.meshgrid(theta, rho)\n",
    "\n",
    "\n",
    "\n",
    "#         # polar_data = np.flipud(np.abs(wavelet_coeffs))\n",
    "#         # DB SACLE\n",
    "#         energy = np.abs(wavelet_coeffs) ** 2\n",
    "#         energy_db = 10* np.log10(energy + 1e-10)\n",
    "#         polar_data = np.flipud(energy_db)\n",
    "\n",
    "\n",
    "#         save_polar_spectrogram(polar_data, T, R, save_path_directory, save_filename, image_size=image_size, dpi=dpi,vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "#         # save_polar_spectrogram(polar_data, T, R, save_path, save_filename, image_size=image_size, dpi=dpi, vmin=vmin, vmax=vmax, cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### img save (30s) : None-Polar(Square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_scalogram(coefficients, save_path, id, cmap, image_size, dpi):\n",
    "#     fig_size_inch = (image_size[0] / dpi, image_size[1] / dpi)\n",
    "#     fig, ax = plt.subplots(figsize=fig_size_inch, dpi=dpi)\n",
    "    \n",
    "# # Apply dB scale for the scalogram\n",
    "# if dbsacle:\n",
    "#     energy = np.abs(coefficients) ** 2\n",
    "#     energy_db = 10 * np.log10(energy + 1e-10)\n",
    "#     c = ax.imshow(energy_db, cmap=cmap, aspect='auto')\n",
    "\n",
    "# # None db sacle\n",
    "# else:\n",
    "\n",
    "#     c = ax.imshow(np.abs(coefficients), cmap=cmap, aspect='auto')\n",
    "    \n",
    "#     # Remove axis for clean image\n",
    "#     ax.axis('off')\n",
    "    \n",
    "#     # Adjust layout to avoid padding\n",
    "#     plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)\n",
    "#     ax.margins(0, 0)\n",
    "#     ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "#     ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "    \n",
    "#     # Save the scalogram image\n",
    "#     plt.savefig(f'{save_path}/{id}.png', format='png', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "#     plt.close()\n",
    "\n",
    "\n",
    "# for label, patient_ids in dic_30.items():\n",
    "#     if label == \"Atrial Fibrillation\":\n",
    "#         folder_name = \"A\"\n",
    "#     elif label == \"Normal Sinus Rhythm\":\n",
    "#         folder_name = \"N\"\n",
    "#     elif label == \"Other Rhythm\":\n",
    "#         folder_name = \"O\"\n",
    "#     elif label == \"Noisy\":\n",
    "#         folder_name = \"~\"\n",
    "\n",
    "#     save_path_directory = os.path.join(base_save_path, folder_name)\n",
    "#     if not os.path.exists(save_path_directory):\n",
    "#         os.makedirs(save_path_directory)\n",
    "\n",
    "#     for patient_id in patient_ids:\n",
    "#         save_filename = f'{patient_id}'\n",
    "#         save_path_img = os.path.join(save_path_directory, f'{save_filename}.png')\n",
    "\n",
    "#         if os.path.exists(save_path_img):\n",
    "#             print(f\"Skipping {patient_id}, already exists.\")\n",
    "#             continue\n",
    "\n",
    "#         print(f\"Processing {patient_id}\")\n",
    "        \n",
    "#         # Load and preprocess ECG data\n",
    "#         ecg_signal, fs = ecg_read(patient_id)\n",
    "        \n",
    "#         if np.isnan(ecg_signal).any():\n",
    "#             ecg_signal = np.nan_to_num(ecg_signal, nan=0.0)\n",
    "\n",
    "#         if PT_denoised:\n",
    "#             pt_tompkins = Pan_tompkins(ecg_signal, fs).fit()\n",
    "#             ecg_signal = pt_tompkins\n",
    "\n",
    "#         if Nomaliztion:\n",
    "#             ecg_signal = normalize_ecg(ecg_signal)                 \n",
    "\n",
    "#         if target_fs != 300:\n",
    "#             ecg_signal = resample_ecg_signal(ecg_signal, fs, target_fs)\n",
    "#             fs = target_fs \n",
    "\n",
    "#         scales = np.arange(1, max_scale + 1)\n",
    "#         wavelet_coeffs, freqs = pywt.cwt(ecg_signal, scales, wavelet, sampling_period=1/fs)\n",
    "\n",
    "#         if np.isnan(wavelet_coeffs).any():\n",
    "#             wavelet_coeffs = np.nan_to_num(wavelet_coeffs, nan=0.0)\n",
    "\n",
    "#         # Save the scalogram\n",
    "#         save_scalogram(wavelet_coeffs, save_path_directory, save_filename, cmap=cmap, image_size=image_size, dpi=dpi, dbscale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### img save (All) : Polar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing A00004\n",
      "Processing A00005\n",
      "Processing A00009\n",
      "Processing A00015\n",
      "Processing A00027\n",
      "Processing A00054\n",
      "Processing A00067\n",
      "Processing A00071\n",
      "Processing A00087\n",
      "Processing A00090\n",
      "Processing A00101\n",
      "Processing A00102\n",
      "Processing A00107\n",
      "Processing A00128\n",
      "Processing A00132\n",
      "Processing A00137\n",
      "Processing A00141\n",
      "Processing A00155\n",
      "Processing A00156\n",
      "Processing A00208\n",
      "Processing A00216\n",
      "Processing A00217\n",
      "Processing A00225\n",
      "Processing A00231\n",
      "Processing A00247\n",
      "Processing A00253\n",
      "Processing A00264\n",
      "Processing A00267\n",
      "Processing A00271\n",
      "Processing A00301\n",
      "Processing A00321\n",
      "Processing A00375\n",
      "Processing A00395\n",
      "Processing A00397\n",
      "Processing A00404\n",
      "Processing A00405\n",
      "Processing A00422\n",
      "Processing A00432\n",
      "Processing A00438\n",
      "Processing A00439\n",
      "Processing A00441\n",
      "Processing A00456\n",
      "Processing A00465\n",
      "Processing A00473\n",
      "Processing A00486\n",
      "Processing A00493\n",
      "Processing A00509\n",
      "Processing A00519\n",
      "Processing A00520\n",
      "Processing A00542\n",
      "Processing A00551\n",
      "Processing A00567\n",
      "Processing A00587\n",
      "Processing A00589\n",
      "Processing A00592\n",
      "Processing A00611\n",
      "Processing A00613\n",
      "Processing A00614\n",
      "Processing A00621\n",
      "Processing A00624\n",
      "Processing A00625\n",
      "Processing A00643\n",
      "Processing A00648\n",
      "Processing A00662\n",
      "Processing A00666\n",
      "Processing A00670\n",
      "Processing A00680\n",
      "Processing A00691\n",
      "Processing A00701\n",
      "Processing A00704\n",
      "Processing A00706\n",
      "Processing A00707\n",
      "Processing A00722\n",
      "Processing A00725\n",
      "Processing A00733\n",
      "Processing A00739\n",
      "Processing A00772\n",
      "Processing A00795\n",
      "Processing A00798\n",
      "Processing A00837\n",
      "Processing A00860\n",
      "Processing A00867\n",
      "Processing A00869\n",
      "Processing A00873\n",
      "Processing A00885\n",
      "Processing A00888\n",
      "Processing A00925\n",
      "Processing A00932\n",
      "Processing A00933\n",
      "Processing A00939\n",
      "Processing A00951\n",
      "Processing A00954\n",
      "Processing A00964\n",
      "Processing A00972\n",
      "Processing A00974\n",
      "Processing A00982\n",
      "Processing A01005\n",
      "Processing A01013\n",
      "Processing A01019\n",
      "Processing A01024\n",
      "Processing A01029\n",
      "Processing A01041\n",
      "Processing A01042\n",
      "Processing A01045\n",
      "Processing A01052\n",
      "Processing A01056\n",
      "Processing A01075\n",
      "Processing A01076\n",
      "Processing A01079\n",
      "Processing A01087\n",
      "Processing A01092\n",
      "Processing A01104\n",
      "Processing A01129\n",
      "Processing A01153\n",
      "Processing A01163\n",
      "Processing A01171\n",
      "Processing A01192\n",
      "Processing A01198\n",
      "Processing A01210\n",
      "Processing A01217\n",
      "Processing A01230\n",
      "Processing A01240\n",
      "Processing A01244\n",
      "Processing A01258\n",
      "Processing A01259\n",
      "Processing A01267\n",
      "Processing A01268\n",
      "Processing A01290\n",
      "Processing A01301\n",
      "Processing A01302\n",
      "Processing A01303\n",
      "Processing A01309\n",
      "Processing A01313\n",
      "Processing A01324\n",
      "Processing A01325\n",
      "Processing A01326\n",
      "Processing A01342\n",
      "Processing A01355\n",
      "Processing A01363\n",
      "Processing A01370\n",
      "Processing A01371\n",
      "Processing A01376\n",
      "Processing A01383\n",
      "Processing A01386\n",
      "Processing A01395\n",
      "Processing A01405\n",
      "Processing A01420\n",
      "Processing A01433\n",
      "Processing A01443\n",
      "Processing A01449\n",
      "Processing A01450\n",
      "Processing A01467\n",
      "Processing A01491\n",
      "Processing A01501\n",
      "Processing A01511\n",
      "Processing A01519\n",
      "Processing A01522\n",
      "Processing A01550\n",
      "Processing A01562\n",
      "Processing A01584\n",
      "Processing A01589\n",
      "Processing A01594\n",
      "Processing A01607\n",
      "Processing A01618\n",
      "Processing A01624\n",
      "Processing A01629\n",
      "Processing A01642\n",
      "Processing A01662\n",
      "Processing A01685\n",
      "Processing A01691\n",
      "Processing A01693\n",
      "Processing A01711\n",
      "Processing A01715\n",
      "Processing A01718\n",
      "Processing A01747\n",
      "Processing A01753\n",
      "Processing A01765\n",
      "Processing A01774\n",
      "Processing A01776\n",
      "Processing A01784\n",
      "Processing A01786\n",
      "Processing A01811\n",
      "Processing A01828\n",
      "Processing A01831\n",
      "Processing A01844\n",
      "Processing A01853\n",
      "Processing A01869\n",
      "Processing A01883\n",
      "Processing A01892\n",
      "Processing A01930\n",
      "Processing A01932\n",
      "Processing A01941\n",
      "Processing A01951\n",
      "Processing A01981\n",
      "Processing A01986\n",
      "Processing A01991\n",
      "Processing A02042\n",
      "Processing A02047\n",
      "Processing A02051\n",
      "Processing A02057\n",
      "Processing A02070\n",
      "Processing A02072\n",
      "Processing A02081\n",
      "Processing A02102\n",
      "Processing A02104\n",
      "Processing A02110\n",
      "Processing A02119\n",
      "Processing A02126\n",
      "Processing A02150\n",
      "Processing A02159\n",
      "Processing A02165\n",
      "Processing A02190\n",
      "Processing A02197\n",
      "Processing A02218\n",
      "Processing A02224\n",
      "Processing A02248\n",
      "Processing A02279\n",
      "Processing A02289\n",
      "Processing A02290\n",
      "Processing A02291\n",
      "Processing A02307\n",
      "Processing A02323\n",
      "Processing A02325\n",
      "Processing A02326\n",
      "Processing A02330\n",
      "Processing A02353\n",
      "Processing A02355\n",
      "Processing A02375\n",
      "Processing A02391\n",
      "Processing A02400\n",
      "Processing A02401\n",
      "Processing A02402\n",
      "Processing A02425\n",
      "Processing A02426\n",
      "Processing A02429\n",
      "Processing A02439\n",
      "Processing A02442\n",
      "Processing A02451\n",
      "Processing A02455\n",
      "Processing A02456\n",
      "Processing A02460\n",
      "Processing A02461\n",
      "Processing A02464\n",
      "Processing A02474\n",
      "Processing A02475\n",
      "Processing A02483\n",
      "Processing A02493\n",
      "Processing A02499\n",
      "Processing A02501\n",
      "Processing A02502\n",
      "Processing A02506\n",
      "Processing A02509\n",
      "Processing A02519\n",
      "Processing A02532\n",
      "Processing A02536\n",
      "Processing A02538\n",
      "Processing A02549\n",
      "Processing A02550\n",
      "Processing A02557\n",
      "Processing A02559\n",
      "Processing A02587\n",
      "Processing A02594\n",
      "Processing A02611\n",
      "Processing A02644\n",
      "Processing A02649\n",
      "Processing A02677\n",
      "Processing A02686\n",
      "Processing A02694\n",
      "Processing A02695\n",
      "Processing A02722\n",
      "Processing A02727\n",
      "Processing A02738\n",
      "Processing A02757\n",
      "Processing A02764\n",
      "Processing A02776\n",
      "Processing A02782\n",
      "Processing A02784\n",
      "Processing A02805\n",
      "Processing A02807\n",
      "Processing A02819\n",
      "Processing A02845\n",
      "Processing A02853\n",
      "Processing A02856\n",
      "Processing A02872\n",
      "Processing A02879\n",
      "Processing A02892\n",
      "Processing A02894\n",
      "Processing A02895\n",
      "Processing A02898\n",
      "Processing A02899\n",
      "Processing A02900\n",
      "Processing A02906\n",
      "Processing A02918\n",
      "Processing A02926\n",
      "Processing A02937\n",
      "Processing A02942\n",
      "Processing A02945\n",
      "Processing A02965\n",
      "Processing A02978\n",
      "Processing A03004\n",
      "Processing A03012\n",
      "Processing A03013\n",
      "Processing A03031\n",
      "Processing A03034\n",
      "Processing A03046\n",
      "Processing A03055\n",
      "Processing A03063\n",
      "Processing A03078\n",
      "Processing A03080\n",
      "Processing A03081\n",
      "Processing A03101\n",
      "Processing A03126\n",
      "Processing A03128\n",
      "Processing A03152\n",
      "Processing A03154\n",
      "Processing A03161\n",
      "Processing A03185\n",
      "Processing A03187\n",
      "Processing A03212\n",
      "Processing A03221\n",
      "Processing A03223\n",
      "Processing A03230\n",
      "Processing A03241\n",
      "Processing A03246\n",
      "Processing A03273\n",
      "Processing A03295\n",
      "Processing A03306\n",
      "Processing A03310\n",
      "Processing A03319\n",
      "Processing A03342\n",
      "Processing A03346\n",
      "Processing A03358\n",
      "Processing A03374\n",
      "Processing A03382\n",
      "Processing A03389\n",
      "Processing A03391\n",
      "Processing A03437\n",
      "Processing A03446\n",
      "Processing A03460\n",
      "Processing A03467\n",
      "Processing A03468\n",
      "Processing A03469\n",
      "Processing A03497\n",
      "Processing A03498\n",
      "Processing A03499\n",
      "Processing A03501\n",
      "Processing A03502\n",
      "Processing A03503\n",
      "Processing A03508\n",
      "Processing A03527\n",
      "Processing A03548\n",
      "Processing A03567\n",
      "Processing A03569\n",
      "Processing A03576\n",
      "Processing A03584\n",
      "Processing A03592\n",
      "Processing A03605\n",
      "Processing A03606\n",
      "Processing A03610\n",
      "Processing A03628\n",
      "Processing A03629\n",
      "Processing A03634\n",
      "Processing A03635\n",
      "Processing A03657\n",
      "Processing A03660\n",
      "Processing A03670\n",
      "Processing A03671\n",
      "Processing A03691\n",
      "Processing A03707\n",
      "Processing A03746\n",
      "Processing A03760\n",
      "Processing A03782\n",
      "Processing A03792\n",
      "Processing A03827\n",
      "Processing A03834\n",
      "Processing A03836\n",
      "Processing A03838\n",
      "Processing A03841\n",
      "Processing A03844\n",
      "Processing A03852\n",
      "Processing A03857\n",
      "Processing A03863\n",
      "Processing A03905\n",
      "Processing A03910\n",
      "Processing A03939\n",
      "Processing A03954\n",
      "Processing A03960\n",
      "Processing A03979\n",
      "Processing A03983\n",
      "Processing A04016\n"
     ]
    }
   ],
   "source": [
    "for label, patient_ids in dic_all.items():\n",
    "    # 해당 리듬에 대한 폴더 생성\n",
    "    if label == \"Atrial Fibrillation\":\n",
    "        folder_name = \"A\"\n",
    "    elif label == \"Normal Sinus Rhythm\":\n",
    "        folder_name = \"N\"\n",
    "    elif label == \"Other Rhythm\":\n",
    "        folder_name = \"O\"\n",
    "    elif label == \"Noisy\":\n",
    "        folder_name = \"~\"\n",
    "\n",
    "    save_path_directory = os.path.join(base_save_path, folder_name)\n",
    "    if not os.path.exists(save_path_directory):\n",
    "        os.makedirs(save_path_directory)\n",
    "\n",
    "    # images_created=0    \n",
    "\n",
    "    for patient_id in patient_ids:\n",
    "        save_filename = f'{patient_id}'\n",
    "        save_path_img = os.path.join(save_path_directory, f'{save_filename}.png')\n",
    "\n",
    "        if os.path.exists(save_path_img):\n",
    "            print(f\"Skipping {patient_id} already exist.\")\n",
    "            continue\n",
    "\n",
    "             # 폴더당 최대 이미지 생성 시\n",
    "        # if images_created >= 10:\n",
    "        #     break\n",
    "        # images_created+=1\n",
    "\n",
    "        print(f\"Processing {patient_id}\")\n",
    "        \n",
    "        ecg_signal, fs = ecg_read(patient_id)\n",
    "        \n",
    "        if np.isnan(ecg_signal).any():\n",
    "            ecg_signal = np.nan_to_num(ecg_signal, nan=0.0)\n",
    "\n",
    "\n",
    "        if PT_denoised:\n",
    "            # try:\n",
    "            #     signals, info = nk.ecg_process(ecg_signal, sampling_rate=fs, method='pantompkins1985')\n",
    "            #     if np.isnan(signals[\"ECG_Clean\"]).any():\n",
    "            #         signals[\"ECG_Clean\"] = np.nan_to_num(signals[\"ECG_Clean\"], nan=0.0)\n",
    "            #     ecg_signal = signals[\"ECG_Clean\"]\n",
    "            # except Exception as e:\n",
    "            #     print(f\"Error processing ECG signal with Pantompkins: {e}\")\n",
    "            #     try:\n",
    "            #         ecg_filtered = nk.ecg_clean(ecg_signal, sampling_rate=fs, method=\"biosppy\")\n",
    "            #         signals, info = nk.ecg_process(ecg_filtered, sampling_rate=fs, method='pantompkins1985')\n",
    "            #         if np.isnan(signals[\"ECG_Clean\"]).any():\n",
    "            #             signals[\"ECG_Clean\"] = np.nan_to_num(signals[\"ECG_Clean\"], nan=0.0)\n",
    "            #         ecg_signal = signals[\"ECG_Clean\"]\n",
    "            #     except Exception as e:\n",
    "            #         print(f\"Error processing ECG signal with Pantompkins after biosppy filtering: {e}\")\n",
    "\n",
    "            pt_tompkins = Pan_tompkins(ecg_signal,fs).fit()\n",
    "            ecg_signal = pt_tompkins\n",
    "\n",
    "        if Nomaliztion:\n",
    "            ecg_signal= normalize_ecg(ecg_signal)       \n",
    "                  \n",
    "\n",
    "        if target_fs != 300:\n",
    "            ecg_signal = resample_ecg_signal(ecg_signal, fs, target_fs)\n",
    "            fs = target_fs \n",
    "        \n",
    "        if padding_length_s ==0 or padding_length_s == None :\n",
    "            padding_length =0\n",
    "            ecg_signal_padded=ecg_signal\n",
    "        else:    \n",
    "            padding_length = int(target_fs / padding_length_s)\n",
    "            # ecg_signal_padded = np.pad(ecg_signal, (padding_length, padding_length), 'constant', constant_values=(0, 0))\n",
    "            ecg_signal_padded = np.pad(ecg_signal, (padding_length, padding_length), mode='reflect')\n",
    "\n",
    "        if alpha:\n",
    "            tukey_window = signal.windows.tukey(len(ecg_signal_padded), alpha=alpha)\n",
    "            ecg_signal_padded *= tukey_window\n",
    "        else:    \n",
    "            ecg_signal_padded=ecg_signal_padded\n",
    "\n",
    "        scales = np.arange(1, max_scale + 1)\n",
    "        wavelet_coeffs, freqs = pywt.cwt(ecg_signal_padded, scales, wavelet, sampling_period=1/fs)\n",
    "\n",
    "        if np.isnan(wavelet_coeffs).any():\n",
    "            wavelet_coeffs = np.nan_to_num(wavelet_coeffs, nan=0.0)\n",
    "\n",
    "        times_padded = np.linspace(0, len(ecg_signal_padded) / fs, len(ecg_signal_padded))\n",
    "        theta = 2 * np.pi * times_padded / max(times_padded)\n",
    "        rho = np.linspace(0.1, max_scale, max_scale)\n",
    "        T, R = np.meshgrid(theta, rho)\n",
    "\n",
    "\n",
    "\n",
    "        polar_data = np.flipud(np.abs(wavelet_coeffs))\n",
    "        # DB SACLE\n",
    "        # energy = np.abs(wavelet_coeffs) ** 2\n",
    "        # energy_db = 10* np.log10(energy + 1e-10)\n",
    "        # polar_data = np.flipud(energy_db)\n",
    "\n",
    "\n",
    "        save_polar_spectrogram(polar_data, T, R, save_path_directory, save_filename, image_size=image_size, dpi=dpi,vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "        # save_polar_spectrogram(polar_data, T, R, save_path, save_filename, image_size=image_size, dpi=dpi, vmin=vmin, vmax=vmax, cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### img save (All) : None-Polar(Square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_scalogram(coefficients, save_path, id, cmap, image_size, dpi, dbsacle):\n",
    "#     fig_size_inch = (image_size[0] / dpi, image_size[1] / dpi)\n",
    "#     fig, ax = plt.subplots(figsize=fig_size_inch, dpi=dpi)\n",
    "    \n",
    "#     # Apply dB scale for the scalogram\n",
    "#     if dbsacle:\n",
    "#         energy = np.abs(coefficients) ** 2\n",
    "#         energy_db = 10 * np.log10(energy + 1e-10)\n",
    "#         c = ax.imshow(energy_db, cmap=cmap, aspect='auto')\n",
    "\n",
    "#     # None db sacle\n",
    "#     else:\n",
    "    \n",
    "#         c = ax.imshow(np.abs(coefficients), cmap=cmap, aspect='auto')\n",
    "    \n",
    "#     # Remove axis for clean image\n",
    "#     ax.axis('off')\n",
    "    \n",
    "#     # Adjust layout to avoid padding\n",
    "#     plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)\n",
    "#     ax.margins(0, 0)\n",
    "#     ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "#     ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "    \n",
    "#     # Save the scalogram image\n",
    "#     plt.savefig(f'{save_path}/{id}.png', format='png', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "#     plt.close()\n",
    "\n",
    "\n",
    "# for label, patient_ids in dic_all.items():\n",
    "#     if label == \"Atrial Fibrillation\":\n",
    "#         folder_name = \"A\"\n",
    "#     elif label == \"Normal Sinus Rhythm\":\n",
    "#         folder_name = \"N\"\n",
    "#     elif label == \"Other Rhythm\":\n",
    "#         folder_name = \"O\"\n",
    "#     elif label == \"Noisy\":\n",
    "#         folder_name = \"~\"\n",
    "\n",
    "#     save_path_directory = os.path.join(base_save_path, folder_name)\n",
    "#     if not os.path.exists(save_path_directory):\n",
    "#         os.makedirs(save_path_directory)\n",
    "\n",
    "#     for patient_id in patient_ids:\n",
    "#         save_filename = f'{patient_id}'\n",
    "#         save_path_img = os.path.join(save_path_directory, f'{save_filename}.png')\n",
    "\n",
    "#         if os.path.exists(save_path_img):\n",
    "#             print(f\"Skipping {patient_id}, already exists.\")\n",
    "#             continue\n",
    "\n",
    "#         print(f\"Processing {patient_id}\")\n",
    "        \n",
    "#         # Load and preprocess ECG data\n",
    "#         ecg_signal, fs = ecg_read(patient_id)\n",
    "        \n",
    "#         if np.isnan(ecg_signal).any():\n",
    "#             ecg_signal = np.nan_to_num(ecg_signal, nan=0.0)\n",
    "\n",
    "#         if PT_denoised:\n",
    "#             pt_tompkins = Pan_tompkins(ecg_signal, fs).fit()\n",
    "#             ecg_signal = pt_tompkins\n",
    "\n",
    "#         if Nomaliztion:\n",
    "#             ecg_signal = normalize_ecg(ecg_signal)                 \n",
    "\n",
    "#         if target_fs != 300:\n",
    "#             ecg_signal = resample_ecg_signal(ecg_signal, fs, target_fs)\n",
    "#             fs = target_fs \n",
    "\n",
    "#         scales = np.arange(1, max_scale + 1)\n",
    "#         wavelet_coeffs, freqs = pywt.cwt(ecg_signal, scales, wavelet, sampling_period=1/fs)\n",
    "\n",
    "#         if np.isnan(wavelet_coeffs).any():\n",
    "#             wavelet_coeffs = np.nan_to_num(wavelet_coeffs, nan=0.0)\n",
    "\n",
    "#         # Save the scalogram\n",
    "#         save_scalogram(wavelet_coeffs, save_path_directory, save_filename, cmap=cmap, image_size=image_size, dpi=dpi, dbsacle=dbscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(base_save_path)\n",
    "\n",
    "# 폴더명 목록\n",
    "folders = [\"A\", \"N\", \"O\", \"~\"]\n",
    "\n",
    "# 각 폴더의 PNG 파일 개수를 세는 함수\n",
    "def count_png_files(folder_name):\n",
    "    count = 0\n",
    "    # 해당 폴더가 존재하는지 확인\n",
    "    if os.path.exists(folder_name):\n",
    "        # 폴더 내의 모든 파일 목록을 가져옴\n",
    "        for file in os.listdir(folder_name):\n",
    "            # 파일이 PNG 확장자를 가지는지 확인\n",
    "            if file.endswith(\".png\"):\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "# 각 폴더의 PNG 파일 개수를 출력\n",
    "total=0\n",
    "for folder in folders:\n",
    "    png_count = count_png_files(folder)\n",
    "    total= png_count+ total\n",
    "    print(f\"Folder '{folder}': {png_count} PNG files\")\n",
    "\n",
    "print(total)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파라미터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# 생성일자\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# 파라미터와 생성일자를 텍스트 파일로 저장\n",
    "params = {\n",
    "    \"sampling_fs\": target_fs,\n",
    "    \"PT_denoised\": PT_denoised,\n",
    "    \"padding_length_s\": padding_length_s,\n",
    "    \"Nomaliztion\": Nomaliztion,\n",
    "    \"alpha\": alpha,\n",
    "    \"max_scale\": max_scale,\n",
    "    \"wavelet\": wavelet,\n",
    "    \"image_size\": image_size,\n",
    "    \"dpi\": dpi,\n",
    "    \"vmin\": vmin,\n",
    "    \"vmax\": vmax,\n",
    "    \"cmap\": cmap,\n",
    "    \"generated_date\": current_date,\n",
    "    \"dbscale\": dbscale,\n",
    "}\n",
    "\n",
    "# 저장할 파일 경로 설정\n",
    "save_path = path  # 텍스트 파일을 저장할 경로를 지정하세요\n",
    "txt_file_path = os.path.join(save_path, '스케일로그램_nonpolar 설명.txt')\n",
    "\n",
    "# 파일에 쓰기\n",
    "with open(txt_file_path, 'w') as f:\n",
    "    f.write(\"[ECG Polar Scalogram]\\n\")\n",
    "    f.write(f\"\\n생성일자:{params['generated_date']}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"#########################\\n\")\n",
    "    f.write(\"ECG 전처리 관련 파라미터:\\n\")\n",
    "    f.write(f\"1. sampling_fs: {params['sampling_fs']}\\n\")\n",
    "    f.write(f\"2. PT_denoised: {params['PT_denoised']}\\n\")\n",
    "    f.write(f\"3. padding_length_s: {params['padding_length_s']}\\n\")\n",
    "    f.write(f\"4. Nomaliztion : {params['Nomaliztion']}\\n\")\n",
    "    f.write(f\"5. alpha: {params['alpha']}\\n\")\n",
    "    f.write(\"#########################\")\n",
    "    f.write(\"\\nScalogram 관련 파라미터:\\n\")\n",
    "    f.write(f\"6. max_scale: {params['max_scale']}\\n\")\n",
    "    f.write(f\"7. wavelet: {params['wavelet']}\\n\")\n",
    "    f.write(\"#########################\")\n",
    "    f.write(\"\\n이미지 저장관련 파라미터:\\n\")\n",
    "    f.write(f\"8.image_size: {params['image_size']}\\n\")\n",
    "    f.write(f\"9. dpi: {params['dpi']}\\n\")\n",
    "    f.write(f\"10. vmin: {params['vmin']}\\n\")\n",
    "    f.write(f\"11. vmax: {params['vmax']}\\n\")\n",
    "    f.write(f\"12. cmap: {params['cmap']}\\n\")\n",
    "    f.write(\"#########################\")\n",
    "\n",
    "print(f\"Parameters and date saved to {txt_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
